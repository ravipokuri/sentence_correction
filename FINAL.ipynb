{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19f6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import seaborn as sns\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import datetime\n",
    "import joblib\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from nltk.translate import bleu_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79646ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_func_1(input_sentence):\n",
    "    tokenizer_sms=joblib.load('tokenizer_sms.pkl')\n",
    "    tokenizer_eng=joblib.load('tokenizer_eng.pkl')\n",
    "    model=load_model('model.h5')\n",
    "    encoder_sms=tokenizer_sms.texts_to_sequences([input_sentence])\n",
    "    encoder_pad=pad_sequences(encoder_sms,maxlen=60,padding='post',dtype='int32')\n",
    "    embed=model.layers[2](encoder_pad)\n",
    "    encoder_out,encoder_h,encoder_c=model.layers[4](embed)\n",
    "    start_index = tokenizer_eng.word_index['<start>']\n",
    "    start_index=np.reshape(start_index,(1,1))\n",
    "    out=[]\n",
    "    for j in range(60):\n",
    "        decemb=model.layers[3](start_index)\n",
    "        decoder_out,decoder_h,decoder_c=model.layers[5](decemb,[encoder_h,encoder_c])\n",
    "        output=model.layers[6](decoder_out)\n",
    "        encoder_h,encoder_c=decoder_h,decoder_c\n",
    "        prob=np.argmax(output)\n",
    "        start_index=np.reshape(prob,(1,1))\n",
    "        out.append(tokenizer_eng.index_word[prob])\n",
    "        if tokenizer_eng.index_word[prob]=='<end>':\n",
    "            break\n",
    "    return ' '.join(out)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa2a6eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not feeling well i am still very sad i am not very sure its a new year evening i think its <end>\n"
     ]
    }
   ],
   "source": [
    "print(final_func_1('everything i think ard 180 to 200 the detail discuss wif the aprent so he interested'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee0b4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_func_2(input_sentence,correct):\n",
    "    tokenizer_sms=joblib.load('tokenizer_sms.pkl')\n",
    "    tokenizer_eng=joblib.load('tokenizer_eng.pkl')\n",
    "    model=load_model('model.h5')\n",
    "    encoder_sms=tokenizer_sms.texts_to_sequences([input_sentence])\n",
    "    encoder_pad=pad_sequences(encoder_sms,maxlen=60,padding='post',dtype='int32')\n",
    "    embed=model.layers[2](encoder_pad)\n",
    "    encoder_out,encoder_h,encoder_c=model.layers[4](embed)\n",
    "    start_index = tokenizer_eng.word_index['<start>']\n",
    "    start_index=np.reshape(start_index,(1,1))\n",
    "    out=[]\n",
    "    for j in range(60):\n",
    "        decemb=model.layers[3](start_index)\n",
    "        decoder_out,decoder_h,decoder_c=model.layers[5](decemb,[encoder_h,encoder_c])\n",
    "        output=model.layers[6](decoder_out)\n",
    "        encoder_h,encoder_c=decoder_h,decoder_c\n",
    "        prob=np.argmax(output)\n",
    "        start_index=np.reshape(prob,(1,1))\n",
    "        out.append(tokenizer_eng.index_word[prob])\n",
    "        if tokenizer_eng.index_word[prob]=='<end>':\n",
    "            break\n",
    "    pred=' '.join(out)  \n",
    "    return bleu_score.sentence_bleu(correct,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7407573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2308298330855597e-231\n"
     ]
    }
   ],
   "source": [
    "print(final_func_2('everything i think ard 180 to 200 the detail discuss wif the aprent so he interested','everything i think around 180 to 200 the details will be discussed with the parent so is he interested <end>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24ac62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
